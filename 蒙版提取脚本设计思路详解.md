# 蒙版标注提取脚本设计思路详解

## 1. 整体流程概述

```
原始输入 → 数据集路径解析 → JSON文件加载 → 蒙版检测 → 结果筛选 → 输出文件列表
```

## 2. 详细流程分析

### 2.1 原始输入文件分析

**输入来源**：四个数据集的配置文件路径
```python
dataset_configs = {
    "z10_label_1230_train": "s3://wangningzi-data-qy/perceptron_files/0102_z10_labels_1900.json",
    "Z10_label_0207_7w": "s3://gongjiahao-share/e2e/test-file/z10_label_0207_1230jsons.json", 
    "z1_label_1230_bmk_qy": "s3://wangningzi-data-qy/perceptron_files/z10_bmk_79.json",
    "BMK_02": "s3://jys-qy/gt_label/linshi/0401/BMK_02.json"
}
```

**配置文件结构**：每个配置文件包含该数据集所有JSON文件的路径列表
```json
{
  "paths": [
    "s3://bucket/dataset1/file1.json",
    "s3://bucket/dataset1/file2.json",
    ...
  ]
}
```
或者直接是路径数组：
```json
[
  "s3://bucket/dataset1/file1.json", 
  "s3://bucket/dataset1/file2.json",
  ...
]
```

### 2.2 数据集路径解析流程

```python
def load_dataset_paths(self):
    for dataset_name, config_path in self.dataset_configs.items():
        # 步骤1: 加载配置文件
        json_data = self.load_json_file(config_path)
        
        # 步骤2: 解析路径列表
        if isinstance(json_data, list):
            paths = json_data  # 直接是路径数组
        elif isinstance(json_data, dict) and "paths" in json_data:
            paths = json_data["paths"]  # 包含paths字段的对象
        
        # 步骤3: 存储到内存
        self.datasets[dataset_name] = paths
```

**解析结果**：
```python
self.datasets = {
    "z10_label_1230_train": ["path1.json", "path2.json", ...],
    "Z10_label_0207_7w": ["path3.json", "path4.json", ...],
    "z1_label_1230_bmk_qy": ["path5.json", "path6.json", ...],
    "BMK_02": ["path7.json", "path8.json", ...]
}
```

### 2.3 单个JSON文件结构分析

**标准JSON文件结构**：
```json
{
  "frames": [
    {
      "labels": [  // 手工标注
        {
          "category": "小汽车",
          "xyz_lidar": {"x": 1.0, "y": 2.0, "z": 3.0},
          "lwh": {"l": 4.0, "w": 2.0, "h": 1.5},
          "yaw_lidar": 0.5,
          "track_length": 10,
          "occlusion": {"camera_15": 0.2, "camera_16": 0.8}
        }
      ],
      "pre_labels": [  // 预标注
        {
          "category": "蒙版",
          "xyz_lidar": {"x": 5.0, "y": 6.0, "z": 7.0},
          ...
        }
      ]
    }
  ],
  "calibrated_sensors": {
    "camera_15": {...},
    "camera_16": {...}
  }
}
```

### 2.4 蒙版检测逻辑详解

基于 `base.py` 中 `_get_single_anno` 方法的逻辑，我实现了四种蒙版检测机制：

#### 2.4.1 直接蒙版类别检测
```python
def check_direct_mask(self, annotation):
    category = annotation.get("category", "").strip()
    mask_categories = {"蒙版", "mask", "masked_area", "正向蒙版", "负向蒙版"}
    return category in mask_categories
```

**检测原理**：直接检查标注的 `category` 字段是否为蒙版相关类别

#### 2.4.2 遮挡阈值检测
```python
def _get_occlusion_attr(self, anno, camera_keys):
    if "occlusion" not in anno:
        return True  # 没有遮挡信息，认为可见
    
    occlusion_dict = anno["occlusion"]
    for camera_key in camera_keys:
        if camera_key in occlusion_dict:
            if occlusion_dict[camera_key] >= self.soft_occ_threshold:
                return True  # 在某个相机中可见
    return False  # 在所有相机中都被遮挡
```

**检测原理**：
- 对应 `base.py` 第223-224行逻辑
- 当 `occlusion_threshold > 0` 且 `not self._get_occlusion_attr()` 时，标注被标记为蒙版
- 检查对象在所有相机中的遮挡程度，如果都被严重遮挡则标记为蒙版

#### 2.4.3 异常值过滤检测
```python
def check_outlier_box(self, annotation):
    category = annotation.get("category", "").strip()
    if category not in self.category_map:
        return False
    
    # 获取3D框尺寸
    l = annotation["lwh"]["l"]
    w = annotation["lwh"]["w"] 
    h = annotation["lwh"]["h"]
    size = np.array([l, w, h])
    
    mapped_category = self.category_map[category]
    
    # 异常值判断规则
    if mapped_category == "pedestrian" and (size > np.array([3, 3, 3])).any():
        return True  # 行人尺寸超过3x3x3米
    elif mapped_category in ["car", "bus", "bicycle"] and (size > np.array([30, 6, 10])).any():
        return True  # 车辆尺寸超过30x6x10米
    
    return False
```

**检测原理**：
- 对应 `base.py` 第225-226行逻辑
- 当 `filter_outlier_boxes = True` 且 `_judge_whether_outlier_box()` 返回True时，标注被标记为蒙版
- 检查3D框尺寸是否超出该类别的合理范围

#### 2.4.4 短轨迹过滤检测
```python
def check_short_track(self, annotation):
    if not self.filter_short_track:
        return False
    return annotation.get("track_length", 2) < 2
```

**检测原理**：
- 对应 `base.py` 第228-229行逻辑
- 当 `filter_short_track = True` 且轨迹长度小于2帧时，标注被标记为蒙版

### 2.5 文件级蒙版检测流程

```python
def analyze_json_file(self, json_path):
    # 步骤1: 加载JSON文件
    json_data = self.load_json_file(json_path)
    
    # 步骤2: 初始化检测状态
    has_mask = False
    mask_reasons = set()
    masked_frames = 0
    
    # 步骤3: 遍历所有帧
    for frame in json_data.get("frames", []):
        frame_has_mask = False
        
        # 步骤4: 检查所有标注（手标+预标）
        all_annotations = []
        all_annotations.extend(frame.get("labels", []))
        all_annotations.extend(frame.get("pre_labels", []))
        
        # 步骤5: 对每个标注应用蒙版检测
        for annotation in all_annotations:
            if self.check_direct_mask(annotation):
                has_mask = True
                frame_has_mask = True
                mask_reasons.add("direct_mask")
            elif self.check_outlier_box(annotation):
                has_mask = True
                frame_has_mask = True
                mask_reasons.add("outlier_box")
            elif self.check_short_track(annotation):
                has_mask = True
                frame_has_mask = True
                mask_reasons.add("short_track")
        
        # 步骤6: 统计包含蒙版的帧
        if frame_has_mask:
            masked_frames += 1
    
    # 步骤7: 返回检测结果
    return {
        "has_mask": has_mask,
        "mask_reasons": list(mask_reasons),
        "total_frames": len(json_data.get("frames", [])),
        "masked_frames": masked_frames,
        "json_path": json_path
    }
```

### 2.6 批量处理流程

```python
def extract_masked_files(self):
    for dataset_name, json_paths in self.datasets.items():
        for json_path in tqdm(json_paths, desc=f"处理 {dataset_name}"):
            # 步骤1: 分析单个文件
            result = self.analyze_json_file(json_path)
            
            # 步骤2: 更新统计信息
            self.statistics[dataset_name]["total_files"] += 1
            self.statistics[dataset_name]["total_frames"] += result["total_frames"]
            
            # 步骤3: 如果包含蒙版，加入结果集
            if result["has_mask"]:
                self.masked_files[dataset_name].append(result)
                self.statistics[dataset_name]["masked_files"] += 1
                self.statistics[dataset_name]["masked_frames"] += result["masked_frames"]
                
                # 步骤4: 统计蒙版原因
                for reason in result["mask_reasons"]:
                    self.statistics[dataset_name][f"reason_{reason}"] += 1
```

### 2.7 结果输出流程

#### 2.7.1 生成文件路径列表
```python
def save_results(self, output_dir="masked_annotations_output"):
    for dataset_name, masked_files in self.masked_files.items():
        # 提取文件路径
        file_paths = [item["json_path"] for item in masked_files]
        
        # 保存为JSON文件
        output_file = os.path.join(output_dir, f"{dataset_name}_masked_files.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(file_paths, f, ensure_ascii=False, indent=2)
```

**输出格式**：
```json
[
  "s3://bucket/dataset1/masked_file1.json",
  "s3://bucket/dataset1/masked_file2.json",
  "s3://bucket/dataset1/masked_file3.json"
]
```

#### 2.7.2 生成统计报告
```python
# 统计信息格式
{
  "z10_label_1230_train": {
    "total_files": 1000,
    "masked_files": 150,
    "total_frames": 50000,
    "masked_frames": 2500,
    "reason_direct_mask": 100,
    "reason_outlier_box": 30,
    "reason_short_track": 20
  }
}
```

## 3. 关键设计决策

### 3.1 为什么检查 labels 和 pre_labels
- `labels`：手工标注，质量高但数量少
- `pre_labels`：预标注，数量多但可能有噪声
- 两者都可能包含蒙版，需要全面检查

### 3.2 为什么使用文件级检测
- 只要文件中任何一帧包含蒙版，整个文件就被标记为包含蒙版
- 符合实际使用需求：需要知道哪些文件包含蒙版数据

### 3.3 为什么记录蒙版原因
- 便于分析蒙版产生的主要原因
- 有助于后续优化标注流程
- 支持按原因进行进一步筛选

## 4. 数据流转示意

```
配置文件路径 → 加载配置 → 解析JSON路径列表
     ↓
JSON文件路径 → 加载JSON → 解析frames数组
     ↓
Frame对象 → 提取labels/pre_labels → 标注对象数组
     ↓
标注对象 → 应用蒙版检测规则 → 蒙版判断结果
     ↓
蒙版判断结果 → 聚合到文件级 → 文件蒙版状态
     ↓
文件蒙版状态 → 筛选包含蒙版的文件 → 最终文件列表
     ↓
最终文件列表 → 按数据集分组 → 输出JSON文件
```

## 5. 性能优化考虑

### 5.1 内存管理
- 逐文件处理，避免一次性加载所有数据
- 及时释放已处理文件的内存

### 5.2 错误处理
- 单个文件处理失败不影响整体流程
- 记录错误信息便于调试

### 5.3 进度显示
- 使用tqdm显示处理进度
- 按数据集分别显示进度

这个设计确保了从原始配置文件到最终筛选结果的完整、可靠的数据处理流程。

## 6. 核心算法伪代码

### 6.1 主流程伪代码
```
MAIN_PROCESS:
  1. 初始化数据结构
  2. FOR each dataset_name, config_path in dataset_configs:
       a. 加载配置文件 → json_data
       b. 解析路径列表 → file_paths[]
       c. 存储到 datasets[dataset_name] = file_paths[]

  3. FOR each dataset_name, file_paths in datasets:
       a. FOR each file_path in file_paths:
            i. 分析文件 → file_result
            ii. 更新统计信息
            iii. IF file_result.has_mask:
                   添加到 masked_files[dataset_name]

  4. 生成输出文件
  5. 生成统计报告
```

### 6.2 文件分析算法伪代码
```
ANALYZE_FILE(json_path):
  1. 加载JSON文件 → json_data
  2. 初始化: has_mask = False, mask_reasons = [], masked_frames = 0

  3. FOR each frame in json_data.frames:
       a. frame_has_mask = False
       b. all_annotations = frame.labels + frame.pre_labels

       c. FOR each annotation in all_annotations:
            i. IF check_direct_mask(annotation):
                 has_mask = True, frame_has_mask = True
                 mask_reasons.add("direct_mask")
            ii. ELIF check_outlier_box(annotation):
                 has_mask = True, frame_has_mask = True
                 mask_reasons.add("outlier_box")
            iii. ELIF check_short_track(annotation):
                 has_mask = True, frame_has_mask = True
                 mask_reasons.add("short_track")

       d. IF frame_has_mask: masked_frames += 1

  4. RETURN {has_mask, mask_reasons, total_frames, masked_frames, json_path}
```

### 6.3 蒙版检测算法伪代码
```
CHECK_DIRECT_MASK(annotation):
  category = annotation.category.strip()
  mask_categories = {"蒙版", "mask", "masked_area", "正向蒙版", "负向蒙版"}
  RETURN category in mask_categories

CHECK_OUTLIER_BOX(annotation):
  IF not filter_outlier_boxes: RETURN False
  IF annotation lacks 3D box info: RETURN False

  size = [annotation.lwh.l, annotation.lwh.w, annotation.lwh.h]
  mapped_category = category_map[annotation.category]

  IF mapped_category == "pedestrian" AND any(size > [3,3,3]):
    RETURN True
  IF mapped_category in ["car","bus","bicycle"] AND any(size > [30,6,10]):
    RETURN True

  RETURN False

CHECK_SHORT_TRACK(annotation):
  IF not filter_short_track: RETURN False
  RETURN annotation.track_length < 2
```

## 7. 实际运行示例

### 7.1 输入示例
假设 `z10_label_1230_train` 配置文件内容：
```json
{
  "paths": [
    "s3://bucket/data1.json",
    "s3://bucket/data2.json",
    "s3://bucket/data3.json"
  ]
}
```

### 7.2 处理过程示例
```
处理 data1.json:
  - 总帧数: 100
  - 第5帧包含直接蒙版标注 → has_mask=True, reason="direct_mask"
  - 第20帧包含异常尺寸车辆 → reason="outlier_box"
  - 结果: 包含蒙版，原因["direct_mask", "outlier_box"]

处理 data2.json:
  - 总帧数: 80
  - 无蒙版标注
  - 结果: 不包含蒙版

处理 data3.json:
  - 总帧数: 120
  - 第10帧包含短轨迹对象 → has_mask=True, reason="short_track"
  - 结果: 包含蒙版，原因["short_track"]
```

### 7.3 输出示例
`z10_label_1230_train_masked_files.json`:
```json
[
  "s3://bucket/data1.json",
  "s3://bucket/data3.json"
]
```

统计信息:
```json
{
  "z10_label_1230_train": {
    "total_files": 3,
    "masked_files": 2,
    "total_frames": 300,
    "masked_frames": 2,
    "reason_direct_mask": 1,
    "reason_outlier_box": 1,
    "reason_short_track": 1
  }
}
```

## 8. 与base.py的对应关系

### 8.1 代码映射关系
| base.py位置 | 脚本中对应方法 | 功能说明 |
|------------|---------------|----------|
| 第223-224行 | `_get_occlusion_attr()` | 遮挡检测 |
| 第225-226行 | `check_outlier_box()` | 异常值过滤 |
| 第228-229行 | `check_short_track()` | 短轨迹过滤 |
| 第220-230行整体逻辑 | `analyze_json_file()` | 综合蒙版判断 |

### 8.2 参数对应关系
| base.py参数 | 脚本中参数 | 默认值 |
|------------|-----------|--------|
| `occlusion_threshold` | `occlusion_threshold` | 1 |
| `filter_outlier_boxes` | `filter_outlier_boxes` | True |
| `filter_short_track` | `filter_short_track` | False |
| `soft_occ_threshold` | `soft_occ_threshold` | 0.4 |

这样的设计确保了脚本完全遵循base.py中的蒙版生成逻辑，保证结果的一致性和准确性。
